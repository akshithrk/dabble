{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL\n",
    "\n",
    "**Answer each of the following questions as well as you can. Feel free to add extra cells to give space for your answers.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You have a MySQL database with a table called `product_sales` structured like**\n",
    "\n",
    "```\n",
    "company_id | product_id | sales | quarter\n",
    "-----------+------------+-------+--------\n",
    "     0     |     1      |  100  |  2016:1\n",
    "                  ...\n",
    "```\n",
    "\n",
    "**one called `company_revenue` like**\n",
    "\n",
    "```\n",
    "company_id | revenue | quarter\n",
    "-----------+---------+--------\n",
    "     0     |   150   |  2016:1\n",
    "             ...\n",
    "```\n",
    "\n",
    "**and one called `product_type` like**\n",
    "\n",
    "```\n",
    "product_id | product_type  \n",
    "-----------+--------------\n",
    "     0     |  smartphone \n",
    "           ...\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **For company 100, write a SQL query for the total sales (over all products) by quarter.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "```\n",
    "SELECT \n",
    "    SUM(sales) AS total_sales\n",
    "FROM \n",
    "    product_sales\n",
    "GROUP BY \n",
    "    company_id,\n",
    "    quarter\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **For company 100, write a query for the total sales for products of type `smartphone` by quarter.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "```\n",
    "SELECT \n",
    "    SUM(sales) AS total_sales\n",
    "FROM \n",
    "    product_sales\n",
    "GROUP BY \n",
    "    product_id,\n",
    "    quarter\n",
    "HAVING\n",
    "    product_id = 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Now assuming an exhaustive list of product types is `smartphone`, `tablet`, and `desktop`, write a query to produce a pivot table like**\n",
    "\n",
    "```\n",
    "        |  smartphone_sales | tablet_sales | desktop_sales\n",
    "company |                   |              |\n",
    "--------+-------------------+--------------+---------------\n",
    "    0   |        100        |     0        |    50\n",
    "    1   |         0         |     100      |    25\n",
    "                          ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "```\n",
    "SELECT\n",
    "    s.company_id,\n",
    "    p.product_type\n",
    "FROM\n",
    "    product_sales s\n",
    "    join product_type p on s.product_id = p.product_id\n",
    "GROUP BY\n",
    "    product_id\n",
    "\n",
    "pivot(\n",
    "  sum(sales)\n",
    "  for product_type in ('smartphone_sales', 'tablet_sales', 'desktop_sales')\n",
    ") piv;\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability, Statistics, and Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **What does \"statistical independence\" mean? What would (gaussian marginal) statistically independent variables look like on a scatter plot?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical independence means that any one event is not correlated to the other or doesnt provide info about the other\n",
    "if the events/variables were correlated there would be a clear +ve/-ve correlation on the scatter plot(regression line). However when statistically independent variables are plotted on a scatter there would be no correlation or no regression on the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Given the following data set (in `df`), compute a 2x2 table for P(Y|X).**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 1000\n",
    "x = np.random.binomial(1, p=0.5, size=N)\n",
    "y = np.random.binomial(1, p=0.4 + 0.5*x)\n",
    "df = pd.DataFrame({'X': x, 'Y': y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **From the previous question, show that P(Y=1|X=0) is statistically significantly different from P(Y=1|X=1). Show your work, and explain your answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **The following data set contains a $Y$ variable, and many $X_i$ variables. Which $X_i$ variables, if any, are useful for predicting $Y$? Be sure to explain your reasoning, and comment your code with explanation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the data is stored locally with the test in data.csv. Make sure you point pandas to the right directory!\n",
    "import pandas as pd\n",
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      int64\n",
       "X_0           float64\n",
       "X_1           float64\n",
       "X_2           float64\n",
       "X_3           float64\n",
       "X_4           float64\n",
       "X_5           float64\n",
       "X_6           float64\n",
       "X_7           float64\n",
       "X_8           float64\n",
       "X_9           float64\n",
       "X_10          float64\n",
       "X_11          float64\n",
       "X_12          float64\n",
       "X_13          float64\n",
       "X_14          float64\n",
       "X_15          float64\n",
       "X_16          float64\n",
       "X_17          float64\n",
       "X_18          float64\n",
       "X_19          float64\n",
       "X_20          float64\n",
       "X_21          float64\n",
       "X_22          float64\n",
       "X_23          float64\n",
       "X_24          float64\n",
       "X_25          float64\n",
       "X_26          float64\n",
       "X_27          float64\n",
       "X_28          float64\n",
       "               ...   \n",
       "X_71          float64\n",
       "X_72          float64\n",
       "X_73          float64\n",
       "X_74          float64\n",
       "X_75          float64\n",
       "X_76          float64\n",
       "X_77          float64\n",
       "X_78          float64\n",
       "X_79          float64\n",
       "X_80          float64\n",
       "X_81          float64\n",
       "X_82          float64\n",
       "X_83          float64\n",
       "X_84          float64\n",
       "X_85          float64\n",
       "X_86          float64\n",
       "X_87          float64\n",
       "X_88          float64\n",
       "X_89          float64\n",
       "X_90          float64\n",
       "X_91          float64\n",
       "X_92          float64\n",
       "X_93          float64\n",
       "X_94          float64\n",
       "X_95          float64\n",
       "X_96          float64\n",
       "X_97          float64\n",
       "X_98          float64\n",
       "X_99          float64\n",
       "Y             float64\n",
       "Length: 102, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>X_0</th>\n",
       "      <th>X_1</th>\n",
       "      <th>X_2</th>\n",
       "      <th>X_3</th>\n",
       "      <th>X_4</th>\n",
       "      <th>X_5</th>\n",
       "      <th>X_6</th>\n",
       "      <th>X_7</th>\n",
       "      <th>X_8</th>\n",
       "      <th>...</th>\n",
       "      <th>X_91</th>\n",
       "      <th>X_92</th>\n",
       "      <th>X_93</th>\n",
       "      <th>X_94</th>\n",
       "      <th>X_95</th>\n",
       "      <th>X_96</th>\n",
       "      <th>X_97</th>\n",
       "      <th>X_98</th>\n",
       "      <th>X_99</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.00000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>24.50000</td>\n",
       "      <td>0.153702</td>\n",
       "      <td>-0.032374</td>\n",
       "      <td>0.014147</td>\n",
       "      <td>-0.216863</td>\n",
       "      <td>0.177577</td>\n",
       "      <td>0.042459</td>\n",
       "      <td>-0.174686</td>\n",
       "      <td>-0.121284</td>\n",
       "      <td>-0.060280</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033087</td>\n",
       "      <td>0.073852</td>\n",
       "      <td>-0.216262</td>\n",
       "      <td>-0.100790</td>\n",
       "      <td>0.086148</td>\n",
       "      <td>-0.195100</td>\n",
       "      <td>0.054315</td>\n",
       "      <td>0.110207</td>\n",
       "      <td>-0.212366</td>\n",
       "      <td>-0.135595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.57738</td>\n",
       "      <td>0.985440</td>\n",
       "      <td>1.305268</td>\n",
       "      <td>0.926229</td>\n",
       "      <td>0.995365</td>\n",
       "      <td>0.953766</td>\n",
       "      <td>1.036020</td>\n",
       "      <td>0.954819</td>\n",
       "      <td>1.092237</td>\n",
       "      <td>0.997873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.989837</td>\n",
       "      <td>0.954284</td>\n",
       "      <td>0.903118</td>\n",
       "      <td>1.070632</td>\n",
       "      <td>1.026285</td>\n",
       "      <td>0.854047</td>\n",
       "      <td>1.238431</td>\n",
       "      <td>1.125329</td>\n",
       "      <td>1.013679</td>\n",
       "      <td>1.352041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>-1.777205</td>\n",
       "      <td>-2.792421</td>\n",
       "      <td>-1.909700</td>\n",
       "      <td>-2.499832</td>\n",
       "      <td>-1.933785</td>\n",
       "      <td>-2.383327</td>\n",
       "      <td>-2.003132</td>\n",
       "      <td>-3.278442</td>\n",
       "      <td>-2.223454</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.395197</td>\n",
       "      <td>-1.978335</td>\n",
       "      <td>-2.554964</td>\n",
       "      <td>-2.671434</td>\n",
       "      <td>-3.007441</td>\n",
       "      <td>-1.719287</td>\n",
       "      <td>-2.820887</td>\n",
       "      <td>-2.582232</td>\n",
       "      <td>-2.451438</td>\n",
       "      <td>-2.589289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.25000</td>\n",
       "      <td>-0.528295</td>\n",
       "      <td>-0.989212</td>\n",
       "      <td>-0.686094</td>\n",
       "      <td>-1.107968</td>\n",
       "      <td>-0.596750</td>\n",
       "      <td>-0.719504</td>\n",
       "      <td>-0.858820</td>\n",
       "      <td>-0.742882</td>\n",
       "      <td>-0.864731</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.649851</td>\n",
       "      <td>-0.712137</td>\n",
       "      <td>-0.600505</td>\n",
       "      <td>-0.829572</td>\n",
       "      <td>-0.472830</td>\n",
       "      <td>-0.907493</td>\n",
       "      <td>-0.785142</td>\n",
       "      <td>-0.525155</td>\n",
       "      <td>-1.064669</td>\n",
       "      <td>-1.178187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>24.50000</td>\n",
       "      <td>0.188693</td>\n",
       "      <td>-0.128964</td>\n",
       "      <td>0.035311</td>\n",
       "      <td>-0.145942</td>\n",
       "      <td>0.178865</td>\n",
       "      <td>0.117989</td>\n",
       "      <td>-0.184938</td>\n",
       "      <td>-0.038906</td>\n",
       "      <td>-0.094358</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.098567</td>\n",
       "      <td>0.149148</td>\n",
       "      <td>-0.165092</td>\n",
       "      <td>-0.141586</td>\n",
       "      <td>0.251252</td>\n",
       "      <td>-0.230819</td>\n",
       "      <td>0.345326</td>\n",
       "      <td>0.026073</td>\n",
       "      <td>-0.251026</td>\n",
       "      <td>-0.300377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>36.75000</td>\n",
       "      <td>0.750674</td>\n",
       "      <td>0.874312</td>\n",
       "      <td>0.650261</td>\n",
       "      <td>0.406322</td>\n",
       "      <td>0.953253</td>\n",
       "      <td>0.791146</td>\n",
       "      <td>0.577431</td>\n",
       "      <td>0.752350</td>\n",
       "      <td>0.469664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.562035</td>\n",
       "      <td>0.681070</td>\n",
       "      <td>0.494838</td>\n",
       "      <td>0.611870</td>\n",
       "      <td>0.795443</td>\n",
       "      <td>0.384572</td>\n",
       "      <td>0.978860</td>\n",
       "      <td>0.905584</td>\n",
       "      <td>0.254832</td>\n",
       "      <td>0.811695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>49.00000</td>\n",
       "      <td>2.904030</td>\n",
       "      <td>2.766002</td>\n",
       "      <td>1.987427</td>\n",
       "      <td>1.638381</td>\n",
       "      <td>2.063600</td>\n",
       "      <td>2.473978</td>\n",
       "      <td>1.716018</td>\n",
       "      <td>2.005324</td>\n",
       "      <td>2.000107</td>\n",
       "      <td>...</td>\n",
       "      <td>2.244686</td>\n",
       "      <td>2.127678</td>\n",
       "      <td>1.461799</td>\n",
       "      <td>2.152128</td>\n",
       "      <td>2.349808</td>\n",
       "      <td>1.661616</td>\n",
       "      <td>2.158857</td>\n",
       "      <td>2.745118</td>\n",
       "      <td>2.519095</td>\n",
       "      <td>3.062367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0        X_0        X_1        X_2        X_3        X_4  \\\n",
       "count    50.00000  50.000000  50.000000  50.000000  50.000000  50.000000   \n",
       "mean     24.50000   0.153702  -0.032374   0.014147  -0.216863   0.177577   \n",
       "std      14.57738   0.985440   1.305268   0.926229   0.995365   0.953766   \n",
       "min       0.00000  -1.777205  -2.792421  -1.909700  -2.499832  -1.933785   \n",
       "25%      12.25000  -0.528295  -0.989212  -0.686094  -1.107968  -0.596750   \n",
       "50%      24.50000   0.188693  -0.128964   0.035311  -0.145942   0.178865   \n",
       "75%      36.75000   0.750674   0.874312   0.650261   0.406322   0.953253   \n",
       "max      49.00000   2.904030   2.766002   1.987427   1.638381   2.063600   \n",
       "\n",
       "             X_5        X_6        X_7        X_8    ...           X_91  \\\n",
       "count  50.000000  50.000000  50.000000  50.000000    ...      50.000000   \n",
       "mean    0.042459  -0.174686  -0.121284  -0.060280    ...      -0.033087   \n",
       "std     1.036020   0.954819   1.092237   0.997873    ...       0.989837   \n",
       "min    -2.383327  -2.003132  -3.278442  -2.223454    ...      -2.395197   \n",
       "25%    -0.719504  -0.858820  -0.742882  -0.864731    ...      -0.649851   \n",
       "50%     0.117989  -0.184938  -0.038906  -0.094358    ...      -0.098567   \n",
       "75%     0.791146   0.577431   0.752350   0.469664    ...       0.562035   \n",
       "max     2.473978   1.716018   2.005324   2.000107    ...       2.244686   \n",
       "\n",
       "            X_92       X_93       X_94       X_95       X_96       X_97  \\\n",
       "count  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000   \n",
       "mean    0.073852  -0.216262  -0.100790   0.086148  -0.195100   0.054315   \n",
       "std     0.954284   0.903118   1.070632   1.026285   0.854047   1.238431   \n",
       "min    -1.978335  -2.554964  -2.671434  -3.007441  -1.719287  -2.820887   \n",
       "25%    -0.712137  -0.600505  -0.829572  -0.472830  -0.907493  -0.785142   \n",
       "50%     0.149148  -0.165092  -0.141586   0.251252  -0.230819   0.345326   \n",
       "75%     0.681070   0.494838   0.611870   0.795443   0.384572   0.978860   \n",
       "max     2.127678   1.461799   2.152128   2.349808   1.661616   2.158857   \n",
       "\n",
       "            X_98       X_99          Y  \n",
       "count  50.000000  50.000000  50.000000  \n",
       "mean    0.110207  -0.212366  -0.135595  \n",
       "std     1.125329   1.013679   1.352041  \n",
       "min    -2.582232  -2.451438  -2.589289  \n",
       "25%    -0.525155  -1.064669  -1.178187  \n",
       "50%     0.026073  -0.251026  -0.300377  \n",
       "75%     0.905584   0.254832   0.811695  \n",
       "max     2.745118   2.519095   3.062367  \n",
       "\n",
       "[8 rows x 102 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "array = df.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-3ec749a87e74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExtraTreesClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 272\u001b[1;33m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpanded_class_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_y_class_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dtype\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mDOUBLE\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_validate_y_class_weight\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    468\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_y_class_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 469\u001b[1;33m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    470\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    471\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    170\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[0;32m    171\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n\u001b[1;32m--> 172\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown label type: %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "# feature extraction\n",
    "model = ExtraTreesClassifier()\n",
    "\n",
    "model.fit(X, Y)\n",
    "#have float type so solving issue below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = ExtraTreesClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = df_int.iloc[:,:101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target = df_int.iloc[:,101:102]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akshi\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_int = df.astype(int)\n",
    "#converting to int as float is not acceptable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01461104  0.00520623  0.0085483   0.02710591  0.00916969  0.01051864\n",
      "  0.00906892  0.00451919  0.00302297  0.00778367  0.00587909  0.021129\n",
      "  0.02341912  0.00403063  0.00801367  0.00467187  0.00968092  0.01832047\n",
      "  0.01714757  0.00322451  0.00914209  0.00683528  0.00481844  0.          0.\n",
      "  0.00564289  0.01317799  0.00302297  0.00478638  0.0242066   0.01733487\n",
      "  0.01078194  0.0077746   0.01544878  0.00451156  0.02675333  0.00334692\n",
      "  0.02098422  0.00476258  0.00394666  0.          0.00860828  0.00541616\n",
      "  0.00302297  0.00705361  0.01669149  0.00935683  0.011663    0.01518526\n",
      "  0.00955153  0.00630949  0.00906892  0.01275407  0.00700322  0.00302297\n",
      "  0.018741    0.00778416  0.00394426  0.01092732  0.00904137  0.01277024\n",
      "  0.01611881  0.          0.00705361  0.01273968  0.00927504  0.00403063\n",
      "  0.01189037  0.          0.00554212  0.01688299  0.00261991  0.00302297\n",
      "  0.00885517  0.01964997  0.01493077  0.00583334  0.01500695  0.\n",
      "  0.02334595  0.0308591   0.03461547  0.00755744  0.00412291  0.03085812\n",
      "  0.00403063  0.01457616  0.01269649  0.          0.00660867  0.\n",
      "  0.02467668  0.01051718  0.00938707  0.01047965  0.0023512   0.\n",
      "  0.00820522  0.00453446  0.00988157  0.00697803]\n"
     ]
    }
   ],
   "source": [
    "print(model.feature_importances_)\n",
    "#higer value is higher importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Using the most appropriate built-in data type (and its associated methods), compute the jaccard similarity between the following lists of items:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = ['a', 'b', 'c', 'd']\n",
    "b = ['c', 'd', 'e', 'f']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Speed up (and time) the following calculation for the sum of the values in the matrix a. Assume you get data marshalling \"for free\". Explain why your approach is faster.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = [[1,2,3,4],\n",
    "     [5,6,7,8],\n",
    "     [9,10,11,12],\n",
    "     [13,14,15,16]]\n",
    "\n",
    "total = 0\n",
    "for row in a:\n",
    "    for value in row:\n",
    "        total += value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Data projects (e.g. building models; showing dashboards; etc.) often require querying for data in real-time. What are some advantages and disadvantages of implementing database queries within your project code (assuming you have many projects)? What is another approach that might help mitigate these issues?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Why is it a better practice to use a context manager for opening files than to manage file objects explicitly on your own?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **What is `async def` used for, and how does it make programs use computing resources more efficiently?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Why do we usually define a train/test split when training a model?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to avoid training entirely on 1 dataset & mainly to evaluate its performance\n",
    "train to train a model\n",
    "test to validate models performance & optimise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **When would you need to define a train/test/validation split, instead of just a train/test split when you're training a model?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Suppose you train a model to predict a real-valued $Y$ from a real-valued $X$ by minimizing mean squared error. Suppose the model has enough capacity, and training works as expected. If you predict the value of $Y$ using some $X$, what is that value of $Y$ an estimator for? How is this quantity different from the predicted value if you had trained by minimizing mean absolute deviation?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **How do you know when a model is overfitting?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "high variance & when the model is sensitive to small variations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **What is a strategy for controlling overfitting? Explain a procedure for using it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regularization\n",
    "depending on dataset size & number of features I would aply L1 for few variables/medium dataset or L2 if many variables/large dataset\n",
    "however it depends on the alpha vlue aswell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **What is bagging, and why does it have a performance limit? What's a common machine learning model that uses bagging?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
